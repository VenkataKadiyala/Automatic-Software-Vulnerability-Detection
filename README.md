# Software Vulnerability Detection using Deep Balance approach 
**Introduction :**

Software vulnerability refers to a defect in software or an OS. Due to their impacts, multiple techniques have been proposed to decrease the results of software vulnerabilities.
Machine-learning is the better strategy to direct this issue and it illustrates vulnerability detection. ML-based methods are employed to train the model using a software system dataset that includes vulnerable and non-vulnerable dataset samples.
Next, the trained model is used to identify the unknown vulnerable samples in the testing data set. We have two major challenges, code representation and class imbalance.
To get the accurate results for detecting vulnerabilities, need to perform a Deep Balance system that combines deep code representation learning and fuzzy based over sampling.

**Data Processing:** 

This analysis includes two projects which are well-known libraries in the open-source community:  **LibPNG,** and **FFmpeg**.
In this, we require vulnerable and non-vulnerable functions. So, I specified 235 vulnerable functions manually and gathered 6,142 non-vulnerable functions from the projects. 
I have collected the labels of vulnerable functions from the National Vulnerability Database (NVD) and the Common Vulnerability and Exposures (CVE) which are known database that contains software vulnerabilities that are encountered earlier.

**AST-based Feature Extraction:**  

To get ASTs, I have used the open-source projects **LibPNG**, and **FFmpeg**. The analysis of ASTs from the source code is significant as a compilation environment should be present when compiling the code. I obtained the ASTs from the source code function with the help of *[CodeSensor](https://github.com/fabsx00/codesensor)* which is a robust parser. 
The *CodeSensor* input is the source code of the program, and the results are the AST of all functions in a serialized format which is used to list the tree view. 
The main aim is to convert these parsed *ASTs* to vectors by maintaining the structural information. 
For accomplishing this, mapping the AST nodes to vector elements using depth-first traversal (DFT). 
So, each node becomes a vector element. As the vector elements indicate the hierarchical position of the AST nodes.
So, it is significant to maintain the sequence of vector elements.
Further to turn textual into a numeric vector, the textual elements of the AST nodes must be tokenized. 
For this, a mapping is created to connect each textual vector element to an integer which represents a token that specifies a textual element. 
Every vector element is substituted with a numerical token and is converted to significant embeddings using Word2Vec.
**Word2Vec** model was trained using the continuous bag-of-words (CBOW) architecture with default settings given by the *Gensim* package. 
Labelled data is not required for the unsupervised training process. So here I trained the Word2Vec model using the code of two open-source projects.
 The results are the dictionary including mappings between each code element and its 100-dimensional vector embedding. 
 
 **LSTM Network for AST-based Representations:**  
 
Handling the length of multiple vectors can be done by applying padding and truncation which obtain combined input vectors length. 
For long sequences, I chose 650 vector elements and applied zeros at the end-of sequence padding for short sequences based on the 
balance between the length and over sparsity of vectors.  
In LSTM network, it estimates the probabilities of vulnerabilities by taking the small amount of converted AST's as input. 
Here “1” designates a vulnerable function and “0” shows a non-vulnerable function. For enabling best performance,
I have arranged the batch size to 64 and the epoch number to 150. 
We have 5756 vulnerable and non-vulnerable codes in which it was splitted the data into 3 parts which includes training, test and validation sets.
Here I have used train_test_split method to get the length of each set after splitting.
The length of training set is 3741, length of validation and test set is 1148, 867 respectively. 

**FOS: Fuzzy-based Oversampling:** 

The dataset has the imbalanced distribution of classes where the majority class has more data samples than the minority class.
Using these classes, we need to detect the software vulnerability. So, it is essential to accurately identify the minority class.
because, when using the imbalanced data sets it is mostly biased on majority class which results in misclassification of minority classes.
Over-sampling methods are used to generate a stable dataset by generating additional instances of the minority class.
The most important technique of oversampling is the **SMOTE** (Synthetic Minority oversampling technique) which concentrates on balancing the distribution
between the training instances of the majority and minority classes by producing additional artificial minority class instances.
The outcomes reveal that the SMOTE method increases the accuracy of classifiers for the minority class. With the updated minority class and majority class,
we can get the balanced trained data which we can use the data in algorithm to achieve Deep Balance Model.

**Instructions:**

There are three folders in github repo which includes Code, Data and Codesenesor
1. In Code folder, we have 6 coding scripts which includes 
      * Codesensor.ipynb- which is used to take input as Data and convert into serialized AST’s
      * AST.ipynb- Take the input as serialized AST’s and convert it into textual vectors
      * Tokens.ipynb- Take inputs as textual vectors and convert it into tokens
      * W2V.ipynb- Take input as textual vectors and convert into 100-dimensions vector
      * Bi-LSTM.ipynb- In this training a Bi-LSTM model, we have 6 layers which will take the numeric one and split them to train, test and validation. And give output as the feature representations. 
      * SMOTE.ipynb- To solve the imbalance problem, SMOTE increases the minority class which helps in getting more accurate results in detecting the vulnerabilities 
2. Data folder consists of vulnerable and non-vulnerable data that was collected from the open-source projects LibPNG, and FFmpeg. The LibPNG contains 44 vulnerable and 577 non vulnerable code functions. FFmpeg includes 191 vulnerable and 5565 non vulnerable code functions.
3. CodeSensor folder which is a robust parser.

**Requirements:**

 - [Tensorflow](https://www.tensorflow.org/).
 - [Keras](https://github.com/kerasteam/keras/tree/master/keras).
 - Python >= 2.7.
 - [CodeSensor](https://github.com/fabsx00/codesensor).
 The dependencies can be installed using [Anaconda](https://www.anaconda.com/products/individual).
